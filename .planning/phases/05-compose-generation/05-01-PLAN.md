---
phase: 05-compose-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - api/internal/compose/stack.go
  - api/internal/api/handlers/stack_compose.go
  - api/internal/api/routes.go
autonomous: true

must_haves:
  truths:
    - "User can preview stack compose YAML before deploying (all enabled instances appear as services)"
    - "User sees warnings about disabled dependency references and port conflicts (no silent failures)"
    - "Each instance container is uniquely named and labeled so two stacks using the same template never collide"
    - "Config files are on disk in compose/stacks/{stack}/{instance}/ before YAML is returned (volumes can reference them)"
    - "Existing single-service compose generation is unchanged (no regressions for services that predate stacks)"
  artifacts:
    - path: "api/internal/compose/stack.go"
      provides: "GenerateStack method and MaterializeStackConfigs"
    - path: "api/internal/api/handlers/stack_compose.go"
      provides: "StackHandler.Compose handler"
    - path: "api/internal/api/routes.go"
      provides: "GET /stacks/{name}/compose route"
  key_links:
    - from: "api/internal/api/handlers/stack_compose.go"
      to: "api/internal/compose/stack.go"
      via: "generator.GenerateStack()"
      pattern: "GenerateStack"
    - from: "api/internal/api/routes.go"
      to: "api/internal/api/handlers/stack_compose.go"
      via: "stackHandler.Compose"
      pattern: "stackHandler\\.Compose"
    - from: "api/internal/compose/stack.go"
      to: "api/internal/container/labels.go"
      via: "container.BuildLabels(stackName, instanceID, strconv.Itoa(templateServiceID))"
      pattern: "container\\.BuildLabels"
---

<objective>
Stack compose generator produces single docker-compose YAML with all instances from effective configs, with config file materialization and warning collection.

Purpose: Core compose generation engine — transforms DB state (template + overrides) into valid docker-compose YAML for an entire stack. This is the data pipeline that Phase 6 (plan/apply) will consume.
Output: New GenerateStack method, MaterializeStackConfigs, compose handler, route wiring.
</objective>

<execution_context>
@/home/priz/.claude/get-shit-done/workflows/execute-plan.md
@/home/priz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@api/internal/compose/generator.go
@api/internal/api/handlers/instance_effective.go
@api/internal/api/handlers/stack.go
@api/internal/api/routes.go
@api/internal/container/labels.go
@api/migrations/017_instance_dependencies.up.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Stack compose generator (GenerateStack + MaterializeStackConfigs)</name>
  <files>api/internal/compose/stack.go</files>
  <action>
Create `api/internal/compose/stack.go` with two methods on the existing `Generator` type. Do NOT modify generator.go — the existing `serviceConfig` struct and `Generate()` method remain untouched.

**GenerateStack(stackName string) ([]byte, []string, error)**

Step 1 — Query stack metadata:
- Query stacks table for network_name WHERE name = $1 AND deleted_at IS NULL. Fallback to "devarch-{stackName}-net" if network_name is NULL.

Step 2 — Query all instances for the stack:
- Query service_instances si JOIN stacks st ON st.id = si.stack_id WHERE st.name = $1 AND si.deleted_at IS NULL AND st.deleted_at IS NULL
- For each instance, load: si.id (int PK), si.instance_id (string), si.enabled, si.container_name, si.template_service_id

Step 3 — Build enabled set and collect warnings for disabled:
- Build `enabledMap map[string]bool` of instance_id -> true for enabled instances
- For disabled instances, add warning: "Skipped disabled instance: {instance_id}"

Step 4 — For each ENABLED instance, load effective config:
- Template base: `SELECT name, image_name, image_tag, restart_policy, command, user_spec FROM services WHERE id = $1` (using template_service_id)
- Effective ports: query instance_ports WHERE instance_id = {si.id}. If none, query service_ports WHERE service_id = {template_service_id}
- Effective volumes: query instance_volumes WHERE instance_id = {si.id}. If none, query service_volumes WHERE service_id = {template_service_id}
- Effective env_vars: load both service_env_vars and instance_env_vars, merge key-based (instance wins). Same logic as mergeEnvVars in instance_effective.go — create local merge helper in stack.go (don't import from handlers package, just replicate the simple map merge)
- Effective labels: load both service_labels and instance_labels, merge key-based (instance wins). Then inject identity labels: call `container.BuildLabels(stackName, instanceID, strconv.Itoa(templateServiceID))` — for each key in the returned map, only add if not already present in merged labels. This ensures user overrides take precedence over system identity labels.
- Effective healthcheck: query instance_healthchecks WHERE instance_id = {si.id}. If sql.ErrNoRows, query service_healthchecks WHERE service_id = {template_service_id}. If still ErrNoRows, nil.
- Effective dependencies: query instance_dependencies WHERE instance_id = {si.id}. If none found, query service_dependencies sd JOIN services s ON s.id = sd.depends_on_service_id WHERE sd.service_id = {template_service_id} (returns service names — for stack generation, these are instance_ids since dependencies reference other instances by instance_id)
- Effective config_files: load both service_config_files and instance_config_files, merge path-based (instance wins)

Step 5 — Build YAML structure using raw map (NOT modifying serviceConfig struct):
Use `map[string]interface{}` for the top-level compose and individual services, since stack generation needs a different depends_on format than the existing serviceConfig allows. This avoids touching generator.go entirely.

```go
type stackCompose struct {
    Networks map[string]networkConfig     `yaml:"networks"`
    Volumes  map[string]interface{}       `yaml:"volumes,omitempty"`
    Services map[string]stackServiceEntry `yaml:"services"`
}

type stackServiceEntry struct {
    Image         string            `yaml:"image,omitempty"`
    ContainerName string            `yaml:"container_name"`
    Restart       string            `yaml:"restart,omitempty"`
    Command       interface{}       `yaml:"command,omitempty"`
    User          string            `yaml:"user,omitempty"`
    Ports         []string          `yaml:"ports,omitempty"`
    Volumes       []string          `yaml:"volumes,omitempty"`
    Environment   map[string]string `yaml:"environment,omitempty"`
    DependsOn     interface{}       `yaml:"depends_on,omitempty"`
    Labels        []string          `yaml:"labels,omitempty"`
    Healthcheck   *healthcheckConfig `yaml:"healthcheck,omitempty"`
    Networks      []string          `yaml:"networks"`
}
```

For each enabled instance, populate stackServiceEntry:
- Service key = instance_id (e.g., "db-01", "redis-cache")
- container_name = si.container_name from DB (already devarch-{stack}-{instance})
- image = "{image_name}:{image_tag}"
- restart = restart_policy
- command = command string if non-empty (use interface{} type, same as existing)
- user = user_spec if non-empty
- ports: format each as "{host_ip}:{host_port}:{container_port}" with "/{protocol}" suffix only if protocol != "tcp"
- volumes: format each as "{source}:{target}" with ":ro" suffix if read_only. Use g.resolveRelativePath for source paths (resolve against stack config materialization path for compose/stacks/* paths)
- environment: map of key->value from merged env vars
- labels: format each as "key=value" strings (includes identity labels from step 4)
- healthcheck: build *healthcheckConfig if non-nil (same struct as generator.go — reuse it)
- networks: []string{networkName}

Step 6 — depends_on handling (CRITICAL — must match CONTEXT.md locked decision):
For each instance's effective dependencies:
- If target instance_id is disabled (not in enabledMap): skip it, add warning "Instance {instance_id}: stripped dependency on disabled instance {target}"
- If target instance_id not found in stack at all (not in any instance's instance_id set): skip it, add warning "Instance {instance_id}: dependency {target} not found in stack"
- If target instance has a healthcheck (check from its loaded effective config): use condition-based map format:
  ```go
  // Produces YAML: depends_on: { db-01: { condition: service_healthy } }
  depMap[target] = map[string]string{"condition": "service_healthy"}
  ```
- If target instance has NO healthcheck: add as plain string to a simple list:
  ```go
  // Produces YAML: depends_on: [redis-cache]
  simpleDeps = append(simpleDeps, target)
  ```
- If ALL deps are simple (no healthchecks): set `DependsOn = simpleDeps` ([]string)
- If ANY dep has healthcheck: merge all into map format — simple deps get `{"condition": "service_started"}`, healthcheck deps get `{"condition": "service_healthy"}`. Set `DependsOn = depMap` (map[string]interface{})
- This means: pure simple deps = simple list. Mixed or all-healthcheck = condition map for all.

Step 7 — Warning collection:
- Port conflicts: collect all (host_ip, host_port) tuples across all enabled instances. Group by host_port. If same host port appears on multiple instances: add warning "Port conflict: host port {port} used by instances {a}, {b}" — warn only, do not block generation.

Step 8 — Marshal and return: `yaml.Marshal(compose)` returns (yamlBytes, warnings, nil).

**MaterializeStackConfigs(stackName, baseDir string) error**
1. Query all enabled instances for the stack and their effective config_files (merge service_config_files + instance_config_files, path-based, instance wins — same merge as step 4 above)
2. Create temp dir: `filepath.Join(baseDir, "compose", "stacks", ".tmp-"+stackName)`
3. For each instance with config files, write to: `tempDir/{instance_id}/{file_path}` with file mode from parseFileMode (reuse from generator.go — it's package-level, accessible)
4. Atomic swap: `os.RemoveAll(finalDir)` then `os.Rename(tempDir, finalDir)` where finalDir = `filepath.Join(baseDir, "compose", "stacks", stackName)`
5. If no instances have config files, still swap (creates empty dir, cleans stale files)
  </action>
  <verify>
Run `cd /home/priz/projects/devarch/api && go build ./...` — must compile with no errors. Confirm generator.go is unmodified: `git diff api/internal/compose/generator.go` should show no changes.
  </verify>
  <done>
GenerateStack method produces multi-service YAML from effective configs. depends_on uses simple list when no healthchecks, condition-based map (service_healthy) when target has healthcheck. Identity labels injected via container.BuildLabels. Disabled instances excluded with warnings. Port conflicts warned. Config files materialized atomically. Existing Generate() completely untouched.
  </done>
</task>

<task type="auto">
  <name>Task 2: Stack compose handler and route wiring</name>
  <files>api/internal/api/handlers/stack_compose.go, api/internal/api/routes.go</files>
  <action>
Create `api/internal/api/handlers/stack_compose.go` with a Compose method on the existing StackHandler:

**StackHandler.Compose(w, r)** — handles GET /api/v1/stacks/{name}/compose
1. Extract stack name from `chi.URLParam(r, "name")`
2. Query stack: `SELECT id, network_name FROM stacks WHERE name = $1 AND deleted_at IS NULL`
3. Return 404 "stack not found" if sql.ErrNoRows
4. Determine networkName: use stack's network_name if non-null, else "devarch-{stackName}-net"
5. Create generator: `compose.NewGenerator(h.db, networkName)` — then set project roots from env vars if available:
   ```go
   gen := compose.NewGenerator(h.db, networkName)
   if root := os.Getenv("PROJECT_ROOT"); root != "" {
       gen.SetProjectRoot(root)
   }
   if hostRoot := os.Getenv("HOST_PROJECT_ROOT"); hostRoot != "" {
       gen.SetHostProjectRoot(hostRoot)
   }
   ```
6. Call `gen.MaterializeStackConfigs(stackName, projectRoot)` first if PROJECT_ROOT is set — ensures config files are on disk before YAML references them via volume mounts
7. Call `gen.GenerateStack(stackName)` to get (yamlBytes, warnings, err)
8. Return 500 on error
9. Return JSON:
   ```go
   w.Header().Set("Content-Type", "application/json")
   json.NewEncoder(w).Encode(map[string]interface{}{
       "yaml":           string(yamlBytes),
       "warnings":       warnings,
       "instance_count": countEnabledInstances, // count from a simple query or parse from YAML
   })
   ```
   For instance_count: simplest approach is a COUNT query: `SELECT COUNT(*) FROM service_instances WHERE stack_id = $1 AND enabled = true AND deleted_at IS NULL`

**Route wiring in routes.go:**
Add inside the existing `r.Route("/{name}", ...)` block under stacks, after the network route (after line `r.Get("/network", stackHandler.NetworkStatus)`):
```go
r.Get("/compose", stackHandler.Compose)
```

No changes needed to NewStackHandler constructor or StackHandler struct — the handler creates a Generator on the fly per request (each stack has different network_name).
  </action>
  <verify>
Run `cd /home/priz/projects/devarch/api && go build ./...` — must compile. Grep routes.go for `/compose` to confirm route is registered under stacks. Verify existing service compose route at line 68 is untouched.
  </verify>
  <done>
GET /api/v1/stacks/{name}/compose returns JSON `{yaml, warnings, instance_count}`. Config files materialized before YAML generation. Route wired in routes.go under stacks/{name}/. Existing service compose endpoint unchanged.
  </done>
</task>

</tasks>

<verification>
1. `cd /home/priz/projects/devarch/api && go build ./...` compiles without errors
2. `git diff api/internal/compose/generator.go` shows NO changes (backward compat: COMP-03)
3. Existing service compose: `GET /api/v1/services/{name}/compose` still returns text/yaml (handler unchanged)
4. New stack compose: `GET /api/v1/stacks/{name}/compose` returns application/json with yaml, warnings, instance_count fields
5. Route registered at correct path under /stacks/{name}/compose
</verification>

<success_criteria>
- Stack compose generator produces valid multi-service YAML from effective configs
- depends_on uses simple list when target has no healthcheck, condition-based service_healthy when target has healthcheck
- Identity labels injected via container.BuildLabels (stack_id, instance_id, template_service_id)
- Disabled instances excluded, dependency references to them stripped with warnings
- Port conflicts detected and warned (non-blocking)
- Config files materialized atomically to compose/stacks/{stack}/{instance}/
- generator.go is completely unmodified (COMP-03 backward compat)
- API compiles and handler returns structured JSON response
</success_criteria>

<output>
After completion, create `.planning/phases/05-compose-generation/05-01-SUMMARY.md`
</output>
